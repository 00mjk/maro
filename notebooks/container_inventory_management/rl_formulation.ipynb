{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "This notebook demonstrates how to use MARO's reinforcement learning (RL) toolkit to solve the container inventory management ([CIM](https://maro.readthedocs.io/en/latest/scenarios/container_inventory_management.html)) problem. It is formalized as a multi-agent reinforcement learning problem, where each port acts as a decision agent. The agents take actions independently, e.g., loading containers to vessels or discharging containers from vessels.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [State Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "State shaper converts the environment observation to the model input state which includes temporal and spatial information. For this scenario, the model input state includes: \n",
    "\n",
    "- Temporal information, including the past week's information of ports and vessels, such as shortage on port and remaining space on vessel. \n",
    "\n",
    "- Spatial information, it including the related downstream port features.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maro.rl import Shaper\n",
    "\n",
    "\n",
    "PORT_ATTRIBUTES = [\"empty\", \"full\", \"on_shipper\", \"on_consignee\", \"booking\", \"shortage\", \"fulfillment\"]\n",
    "VESSEL_ATTRIBUTES = [\"empty\", \"full\", \"remaining_space\"]\n",
    "LOOK_BACK = 7\n",
    "MAX_PORTS_DOWNSTREAM = 2\n",
    "\n",
    "\n",
    "class CIMStateShaper(Shaper):\n",
    "    def __init__(self, *, look_back, max_ports_downstream):\n",
    "        super().__init__()\n",
    "        self._look_back = look_back\n",
    "        self._max_ports_downstream = max_ports_downstream\n",
    "\n",
    "    def __call__(self, decision_event, snapshot_list):\n",
    "        tick, port_idx, vessel_idx = decision_event.tick, decision_event.port_idx, decision_event.vessel_idx\n",
    "        ticks = [tick - rt for rt in range(self._look_back - 1)]\n",
    "        future_port_idx_list = snapshot_list[\"vessels\"][tick: vessel_idx: 'future_stop_list'].astype('int')\n",
    "        port_features = snapshot_list[\"ports\"][ticks: [port_idx] + list(future_port_idx_list): PORT_ATTRIBUTES]\n",
    "        vessel_features = snapshot_list[\"vessels\"][tick: vessel_idx: VESSEL_ATTRIBUTES]\n",
    "        state = np.concatenate((port_features, vessel_features))\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Action Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Action shaper is used to convert an agent's model output to an environment executable action. For this specific scenario, the output is a discrete index that corresponds to a percentage indicating the fraction of containers to be loaded to or discharged from the arriving vessel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.simulator.scenarios.cim.common import Action, ActionType\n",
    "\n",
    "\n",
    "class CIMActionShaper(Shaper):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self._action_space = action_space\n",
    "        self._zero_action_index = action_space.index(0)\n",
    "\n",
    "    def __call__(self, model_action, decision_event, snapshot_list):\n",
    "        scope = decision_event.action_scope\n",
    "        tick = decision_event.tick\n",
    "        port_idx = decision_event.port_idx\n",
    "        vessel_idx = decision_event.vessel_idx\n",
    "\n",
    "        port_empty = snapshot_list[\"ports\"][tick: port_idx: [\"empty\", \"full\", \"on_shipper\", \"on_consignee\"]][0]\n",
    "        vessel_remaining_space = snapshot_list[\"vessels\"][tick: vessel_idx: [\"empty\", \"full\", \"remaining_space\"]][2]\n",
    "        early_discharge = snapshot_list[\"vessels\"][tick:vessel_idx: \"early_discharge\"][0]\n",
    "        assert 0 <= model_action < len(self._action_space)\n",
    "        operation_num = self._action_space[model_action]\n",
    "\n",
    "        if model_action < self._zero_action_index:\n",
    "            actual_action = max(round(operation_num * port_empty), -vessel_remaining_space)\n",
    "            action_type = ActionType.LOAD\n",
    "        elif model_action > self._zero_action_index:\n",
    "            plan_action = operation_num * (scope.discharge + early_discharge) - early_discharge\n",
    "            actual_action = round(plan_action) if plan_action > 0 else round(operation_num * scope.discharge)\n",
    "            action_type = ActionType.DISCHARGE\n",
    "        else:\n",
    "            actual_action = 0\n",
    "            action_type = None\n",
    "\n",
    "        return Action(vessel_idx, port_idx, abs(actual_action), action_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Experience Shaper](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#shapers)\n",
    "\n",
    "Experience shaper is used to convert an episode trajectory to trainable experiences for RL agents. For this specific scenario, the reward is a linear combination of fulfillment and shortage in a limited time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class CIMExperienceShaper(Shaper):\n",
    "    def __init__(self, *, time_window, time_decay_factor, fulfillment_factor, shortage_factor):\n",
    "        super().__init__(reward_func=None)\n",
    "        self._time_window = time_window\n",
    "        self._time_decay_factor = time_decay_factor\n",
    "        self._fulfillment_factor = fulfillment_factor\n",
    "        self._shortage_factor = shortage_factor\n",
    "        self._trajectory = {key: [] for key in [\"state\", \"action\", \"agent_id\", \"event\"]}\n",
    "    \n",
    "    def __call__(self, snapshot_list):\n",
    "        states = self._trajectory[\"state\"]\n",
    "        actions = self._trajectory[\"action\"]\n",
    "        agent_ids = self._trajectory[\"agent_id\"]\n",
    "        events = self._trajectory[\"event\"]\n",
    "\n",
    "        experiences_by_agent = defaultdict(lambda: defaultdict(list))\n",
    "        for i in range(len(states) - 1):\n",
    "            experiences = experiences_by_agent[agent_ids[i]]\n",
    "            experiences[\"state\"].append(states[i])\n",
    "            experiences[\"action\"].append(actions[i])\n",
    "            experiences[\"reward\"].append(self._compute_reward(events[i], snapshot_list))\n",
    "            experiences[\"next_state\"].append(states[i + 1])\n",
    "\n",
    "        return dict(experiences_by_agent)\n",
    "\n",
    "    def record(self, transition):\n",
    "        for key, val in transition.items():\n",
    "            self._trajectory[key].append(val)\n",
    "\n",
    "    def reset(self):\n",
    "        self._trajectory = {key: [] for key in [\"state\", \"action\", \"agent_id\", \"event\"]}\n",
    "\n",
    "    def _compute_reward(self, decision_event, snapshot_list):\n",
    "        start_tick = decision_event.tick + 1\n",
    "        end_tick = decision_event.tick + self._time_window\n",
    "        ticks = list(range(start_tick, end_tick))\n",
    "\n",
    "        # calculate tc reward\n",
    "        future_fulfillment = snapshot_list[\"ports\"][ticks::\"fulfillment\"]\n",
    "        future_shortage = snapshot_list[\"ports\"][ticks::\"shortage\"]\n",
    "        decay_list = [\n",
    "            self._time_decay_factor ** i for i in range(end_tick - start_tick)\n",
    "            for _ in range(future_fulfillment.shape[0] // (end_tick - start_tick))\n",
    "        ]\n",
    "\n",
    "        tot_fulfillment = np.dot(future_fulfillment, decay_list)\n",
    "        tot_shortage = np.dot(future_shortage, decay_list)\n",
    "\n",
    "        return np.float32(self._fulfillment_factor * tot_fulfillment - self._shortage_factor * tot_shortage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#agent)\n",
    "\n",
    "For this scenario, the agent is the algorithmic abstraction of a port. We choose DQN as our underlying learning algorithm with a TD-error-based sampling mechanism.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import smooth_l1_loss\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from maro.rl import DQN, DQNConfig, FullyConnectedBlock, OptimOption, SimpleMultiHeadModel, SimpleStore\n",
    "from maro.utils import set_seeds\n",
    "\n",
    "\n",
    "input_dim = (LOOK_BACK + 1) * (MAX_PORTS_DOWNSTREAM + 1) * len(PORT_ATTRIBUTES) + len(VESSEL_ATTRIBUTES)\n",
    "\n",
    "def create_dqn_agents(agent_id_list):\n",
    "    set_seeds(64)  # for reproducibility\n",
    "    agent_dict = {}\n",
    "    for agent_id in agent_id_list:\n",
    "        q_net = FullyConnectedBlock(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=[256, 128, 64],\n",
    "            output_dim=21,  # action space [0, 1, ..., 20]\n",
    "            activation=nn.LeakyReLU,\n",
    "            is_head=True,\n",
    "            batch_norm=True, \n",
    "            softmax=False,\n",
    "            skip_connection=False,\n",
    "            dropout_p=.0\n",
    "        )\n",
    "\n",
    "        agent_dict[agent_id] = DQN( \n",
    "            SimpleMultiHeadModel(\n",
    "                q_net, optim_option=OptimOption(optim_cls=RMSprop, optim_params={\"lr\": 0.05})\n",
    "            ),\n",
    "            DQNConfig(\n",
    "                reward_discount=.0, \n",
    "                min_exp_to_train=1024,\n",
    "                num_batches=10,\n",
    "                batch_size=128, \n",
    "                target_update_freq=5, \n",
    "                tau=0.1, \n",
    "                is_double=True, \n",
    "                per_sample_td_error=True,\n",
    "                loss_cls=nn.SmoothL1Loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return agent_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Roll-out Executor](https://maro.readthedocs.io/en/latest/key_components/rl_toolkit.html#rollout_executor)\n",
    "\n",
    "A roll-out executor consists of an environment instance, an agent (a single agent or multiple agents wrapped by MultiAgentWrapper) and optional shapers for necessary conversions. It implements the ``roll_out`` method where the agent interacts with the environment for one full episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maro.rl import AbsRolloutExecutor\n",
    "\n",
    "\n",
    "class SimpleRolloutExecutor(AbsRolloutExecutor):\n",
    "    def __init__(self, env, agent, state_shaper, action_shaper, experience_shaper):\n",
    "        super().__init__(\n",
    "            env, agent, \n",
    "            state_shaper=state_shaper, action_shaper=action_shaper, experience_shaper=experience_shaper\n",
    "        )\n",
    "\n",
    "    def roll_out(self, index, training=True):\n",
    "        self.env.reset()\n",
    "        metrics, event, is_done = self.env.step(None)\n",
    "        while not is_done:\n",
    "            state = self.state_shaper(event, self.env.snapshot_list)\n",
    "            agent_id = str(event.port_idx)\n",
    "            action = self.agent[agent_id].choose_action(state)\n",
    "            self.experience_shaper.record(\n",
    "                {\"state\": state, \"agent_id\": agent_id, \"event\": event, \"action\": action}\n",
    "            )\n",
    "            metrics, event, is_done = self.env.step(self.action_shaper(action, event, self.env.snapshot_list))\n",
    "\n",
    "        exp = self.experience_shaper(self.env.snapshot_list) if training else None\n",
    "        self.experience_shaper.reset()\n",
    "\n",
    "        return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop\n",
    "\n",
    "This code cell demonstrates the typical workflow of a learning policy's interaction with a MARO environment. \n",
    "\n",
    "- Initialize an environment with specific scenario and topology parameters. \n",
    "\n",
    "- Create agents and shapers. \n",
    "\n",
    "- Execute the training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0 - metrics: {'order_requirements': 2240000, 'container_shortage': 1352136, 'operation_number': 3254760}, exploration_params: {'epsilon': 0.4}\n",
      "ep 1 - metrics: {'order_requirements': 2240000, 'container_shortage': 1249849, 'operation_number': 3426101}, exploration_params: {'epsilon': 0.39840000000000003}\n",
      "ep 2 - metrics: {'order_requirements': 2240000, 'container_shortage': 1174857, 'operation_number': 3816050}, exploration_params: {'epsilon': 0.39680000000000004}\n",
      "ep 3 - metrics: {'order_requirements': 2240000, 'container_shortage': 1168029, 'operation_number': 3783409}, exploration_params: {'epsilon': 0.39520000000000005}\n",
      "ep 4 - metrics: {'order_requirements': 2240000, 'container_shortage': 1478014, 'operation_number': 3503012}, exploration_params: {'epsilon': 0.39360000000000006}\n",
      "ep 5 - metrics: {'order_requirements': 2240000, 'container_shortage': 1450497, 'operation_number': 4235336.0}, exploration_params: {'epsilon': 0.39200000000000007}\n",
      "ep 6 - metrics: {'order_requirements': 2240000, 'container_shortage': 1250538, 'operation_number': 3681417}, exploration_params: {'epsilon': 0.3904000000000001}\n",
      "ep 7 - metrics: {'order_requirements': 2240000, 'container_shortage': 1923270, 'operation_number': 2793886}, exploration_params: {'epsilon': 0.3888000000000001}\n",
      "ep 8 - metrics: {'order_requirements': 2240000, 'container_shortage': 1621199, 'operation_number': 2655534}, exploration_params: {'epsilon': 0.3872000000000001}\n",
      "ep 9 - metrics: {'order_requirements': 2240000, 'container_shortage': 1185373, 'operation_number': 3303864}, exploration_params: {'epsilon': 0.3856000000000001}\n",
      "ep 10 - metrics: {'order_requirements': 2240000, 'container_shortage': 720509, 'operation_number': 3923254}, exploration_params: {'epsilon': 0.3840000000000001}\n",
      "ep 11 - metrics: {'order_requirements': 2240000, 'container_shortage': 604046, 'operation_number': 4055816}, exploration_params: {'epsilon': 0.38240000000000013}\n",
      "ep 12 - metrics: {'order_requirements': 2240000, 'container_shortage': 721395, 'operation_number': 4088165}, exploration_params: {'epsilon': 0.38080000000000014}\n",
      "ep 13 - metrics: {'order_requirements': 2240000, 'container_shortage': 569133, 'operation_number': 5024948}, exploration_params: {'epsilon': 0.37920000000000015}\n",
      "ep 14 - metrics: {'order_requirements': 2240000, 'container_shortage': 672845, 'operation_number': 4619933}, exploration_params: {'epsilon': 0.37760000000000016}\n",
      "ep 15 - metrics: {'order_requirements': 2240000, 'container_shortage': 899736, 'operation_number': 4688569}, exploration_params: {'epsilon': 0.37600000000000017}\n",
      "ep 16 - metrics: {'order_requirements': 2240000, 'container_shortage': 950907, 'operation_number': 4453843}, exploration_params: {'epsilon': 0.3744000000000002}\n",
      "ep 17 - metrics: {'order_requirements': 2240000, 'container_shortage': 642622, 'operation_number': 5087980}, exploration_params: {'epsilon': 0.3728000000000002}\n",
      "ep 18 - metrics: {'order_requirements': 2240000, 'container_shortage': 804926, 'operation_number': 4627842}, exploration_params: {'epsilon': 0.3712000000000002}\n",
      "ep 19 - metrics: {'order_requirements': 2240000, 'container_shortage': 955385, 'operation_number': 4955868}, exploration_params: {'epsilon': 0.3696000000000002}\n",
      "ep 20 - metrics: {'order_requirements': 2240000, 'container_shortage': 829930, 'operation_number': 5148070}, exploration_params: {'epsilon': 0.3680000000000002}\n",
      "ep 21 - metrics: {'order_requirements': 2240000, 'container_shortage': 644572, 'operation_number': 5105741}, exploration_params: {'epsilon': 0.3664000000000002}\n",
      "ep 22 - metrics: {'order_requirements': 2240000, 'container_shortage': 555530, 'operation_number': 4839572}, exploration_params: {'epsilon': 0.36480000000000024}\n",
      "ep 23 - metrics: {'order_requirements': 2240000, 'container_shortage': 1031378, 'operation_number': 3728440}, exploration_params: {'epsilon': 0.36320000000000024}\n",
      "ep 24 - metrics: {'order_requirements': 2240000, 'container_shortage': 723926, 'operation_number': 5235602}, exploration_params: {'epsilon': 0.36160000000000025}\n",
      "ep 25 - metrics: {'order_requirements': 2240000, 'container_shortage': 676156, 'operation_number': 5142291}, exploration_params: {'epsilon': 0.36000000000000026}\n",
      "ep 26 - metrics: {'order_requirements': 2240000, 'container_shortage': 842840, 'operation_number': 5028770}, exploration_params: {'epsilon': 0.3584000000000003}\n",
      "ep 27 - metrics: {'order_requirements': 2240000, 'container_shortage': 865620, 'operation_number': 4766610}, exploration_params: {'epsilon': 0.3568000000000003}\n",
      "ep 28 - metrics: {'order_requirements': 2240000, 'container_shortage': 794776, 'operation_number': 5052284}, exploration_params: {'epsilon': 0.3552000000000003}\n",
      "ep 29 - metrics: {'order_requirements': 2240000, 'container_shortage': 699853, 'operation_number': 5152245}, exploration_params: {'epsilon': 0.3536000000000003}\n",
      "ep 30 - metrics: {'order_requirements': 2240000, 'container_shortage': 616300, 'operation_number': 4678601}, exploration_params: {'epsilon': 0.3520000000000003}\n",
      "ep 31 - metrics: {'order_requirements': 2240000, 'container_shortage': 728820, 'operation_number': 4974799}, exploration_params: {'epsilon': 0.3504000000000003}\n",
      "ep 32 - metrics: {'order_requirements': 2240000, 'container_shortage': 727185, 'operation_number': 4755672}, exploration_params: {'epsilon': 0.34880000000000033}\n",
      "ep 33 - metrics: {'order_requirements': 2240000, 'container_shortage': 727381, 'operation_number': 4873634}, exploration_params: {'epsilon': 0.34720000000000034}\n",
      "ep 34 - metrics: {'order_requirements': 2240000, 'container_shortage': 679647, 'operation_number': 4624782}, exploration_params: {'epsilon': 0.34560000000000035}\n",
      "ep 35 - metrics: {'order_requirements': 2240000, 'container_shortage': 625849, 'operation_number': 4947661}, exploration_params: {'epsilon': 0.34400000000000036}\n",
      "ep 36 - metrics: {'order_requirements': 2240000, 'container_shortage': 706626, 'operation_number': 4546677}, exploration_params: {'epsilon': 0.34240000000000037}\n",
      "ep 37 - metrics: {'order_requirements': 2240000, 'container_shortage': 560302, 'operation_number': 4578177}, exploration_params: {'epsilon': 0.3408000000000004}\n",
      "ep 38 - metrics: {'order_requirements': 2240000, 'container_shortage': 774175, 'operation_number': 5005750}, exploration_params: {'epsilon': 0.3392000000000004}\n",
      "ep 39 - metrics: {'order_requirements': 2240000, 'container_shortage': 584020, 'operation_number': 4787339}, exploration_params: {'epsilon': 0.3376000000000004}\n",
      "ep 40 - metrics: {'order_requirements': 2240000, 'container_shortage': 576394, 'operation_number': 4720419}, exploration_params: {'epsilon': 0.3360000000000004}\n",
      "ep 41 - metrics: {'order_requirements': 2240000, 'container_shortage': 702115, 'operation_number': 4928421}, exploration_params: {'epsilon': 0.3344000000000004}\n",
      "ep 42 - metrics: {'order_requirements': 2240000, 'container_shortage': 822003, 'operation_number': 5127494}, exploration_params: {'epsilon': 0.33280000000000043}\n",
      "ep 43 - metrics: {'order_requirements': 2240000, 'container_shortage': 676856, 'operation_number': 4361711}, exploration_params: {'epsilon': 0.33120000000000044}\n",
      "ep 44 - metrics: {'order_requirements': 2240000, 'container_shortage': 669537, 'operation_number': 5291246}, exploration_params: {'epsilon': 0.32960000000000045}\n",
      "ep 45 - metrics: {'order_requirements': 2240000, 'container_shortage': 569000, 'operation_number': 4652232}, exploration_params: {'epsilon': 0.32800000000000046}\n",
      "ep 46 - metrics: {'order_requirements': 2240000, 'container_shortage': 604969, 'operation_number': 5123438}, exploration_params: {'epsilon': 0.32640000000000047}\n",
      "ep 47 - metrics: {'order_requirements': 2240000, 'container_shortage': 557511, 'operation_number': 4832546}, exploration_params: {'epsilon': 0.3248000000000005}\n",
      "ep 48 - metrics: {'order_requirements': 2240000, 'container_shortage': 661551, 'operation_number': 4916774}, exploration_params: {'epsilon': 0.3232000000000005}\n",
      "ep 49 - metrics: {'order_requirements': 2240000, 'container_shortage': 678443, 'operation_number': 4797744}, exploration_params: {'epsilon': 0.3216000000000005}\n",
      "ep 50 - metrics: {'order_requirements': 2240000, 'container_shortage': 647478, 'operation_number': 4983993}, exploration_params: {'epsilon': 0.3200000000000005}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 51 - metrics: {'order_requirements': 2240000, 'container_shortage': 436833, 'operation_number': 4411942}, exploration_params: {'epsilon': 0.3134693877551025}\n",
      "ep 52 - metrics: {'order_requirements': 2240000, 'container_shortage': 626074, 'operation_number': 4618660}, exploration_params: {'epsilon': 0.30693877551020454}\n",
      "ep 53 - metrics: {'order_requirements': 2240000, 'container_shortage': 708019, 'operation_number': 4538794}, exploration_params: {'epsilon': 0.30040816326530656}\n",
      "ep 54 - metrics: {'order_requirements': 2240000, 'container_shortage': 704531, 'operation_number': 5035620}, exploration_params: {'epsilon': 0.2938775510204086}\n",
      "ep 55 - metrics: {'order_requirements': 2240000, 'container_shortage': 675365, 'operation_number': 4744667}, exploration_params: {'epsilon': 0.2873469387755106}\n",
      "ep 56 - metrics: {'order_requirements': 2240000, 'container_shortage': 536896, 'operation_number': 4664484}, exploration_params: {'epsilon': 0.2808163265306126}\n",
      "ep 57 - metrics: {'order_requirements': 2240000, 'container_shortage': 517742, 'operation_number': 4515999}, exploration_params: {'epsilon': 0.27428571428571463}\n",
      "ep 58 - metrics: {'order_requirements': 2240000, 'container_shortage': 495825, 'operation_number': 4592775}, exploration_params: {'epsilon': 0.26775510204081665}\n",
      "ep 59 - metrics: {'order_requirements': 2240000, 'container_shortage': 485726, 'operation_number': 4586843}, exploration_params: {'epsilon': 0.26122448979591867}\n",
      "ep 60 - metrics: {'order_requirements': 2240000, 'container_shortage': 350307, 'operation_number': 4856216}, exploration_params: {'epsilon': 0.2546938775510207}\n",
      "ep 61 - metrics: {'order_requirements': 2240000, 'container_shortage': 440101, 'operation_number': 4511357}, exploration_params: {'epsilon': 0.24816326530612273}\n",
      "ep 62 - metrics: {'order_requirements': 2240000, 'container_shortage': 366995, 'operation_number': 4489751}, exploration_params: {'epsilon': 0.24163265306122478}\n",
      "ep 63 - metrics: {'order_requirements': 2240000, 'container_shortage': 407148, 'operation_number': 4229339}, exploration_params: {'epsilon': 0.23510204081632682}\n",
      "ep 64 - metrics: {'order_requirements': 2240000, 'container_shortage': 490311, 'operation_number': 4231013}, exploration_params: {'epsilon': 0.22857142857142887}\n",
      "ep 65 - metrics: {'order_requirements': 2240000, 'container_shortage': 495735, 'operation_number': 4084791}, exploration_params: {'epsilon': 0.22204081632653092}\n",
      "ep 66 - metrics: {'order_requirements': 2240000, 'container_shortage': 531423, 'operation_number': 4125375}, exploration_params: {'epsilon': 0.21551020408163296}\n",
      "ep 67 - metrics: {'order_requirements': 2240000, 'container_shortage': 530556, 'operation_number': 4015393}, exploration_params: {'epsilon': 0.208979591836735}\n",
      "ep 68 - metrics: {'order_requirements': 2240000, 'container_shortage': 271291, 'operation_number': 4631212}, exploration_params: {'epsilon': 0.20244897959183705}\n",
      "ep 69 - metrics: {'order_requirements': 2240000, 'container_shortage': 355445, 'operation_number': 4429670}, exploration_params: {'epsilon': 0.1959183673469391}\n",
      "ep 70 - metrics: {'order_requirements': 2240000, 'container_shortage': 358595, 'operation_number': 4645877}, exploration_params: {'epsilon': 0.18938775510204114}\n",
      "ep 71 - metrics: {'order_requirements': 2240000, 'container_shortage': 269327, 'operation_number': 4763005}, exploration_params: {'epsilon': 0.1828571428571432}\n",
      "ep 72 - metrics: {'order_requirements': 2240000, 'container_shortage': 252523, 'operation_number': 4390522}, exploration_params: {'epsilon': 0.17632653061224524}\n",
      "ep 73 - metrics: {'order_requirements': 2240000, 'container_shortage': 224338, 'operation_number': 4651297}, exploration_params: {'epsilon': 0.16979591836734728}\n",
      "ep 74 - metrics: {'order_requirements': 2240000, 'container_shortage': 419598, 'operation_number': 4577744}, exploration_params: {'epsilon': 0.16326530612244933}\n",
      "ep 75 - metrics: {'order_requirements': 2240000, 'container_shortage': 319832, 'operation_number': 4523035}, exploration_params: {'epsilon': 0.15673469387755137}\n",
      "ep 76 - metrics: {'order_requirements': 2240000, 'container_shortage': 291227, 'operation_number': 4569509}, exploration_params: {'epsilon': 0.15020408163265342}\n",
      "ep 77 - metrics: {'order_requirements': 2240000, 'container_shortage': 235975, 'operation_number': 4438580}, exploration_params: {'epsilon': 0.14367346938775546}\n",
      "ep 78 - metrics: {'order_requirements': 2240000, 'container_shortage': 209720, 'operation_number': 4472226}, exploration_params: {'epsilon': 0.1371428571428575}\n",
      "ep 79 - metrics: {'order_requirements': 2240000, 'container_shortage': 203721, 'operation_number': 4475482}, exploration_params: {'epsilon': 0.13061224489795956}\n",
      "ep 80 - metrics: {'order_requirements': 2240000, 'container_shortage': 215189, 'operation_number': 4290320}, exploration_params: {'epsilon': 0.1240816326530616}\n",
      "ep 81 - metrics: {'order_requirements': 2240000, 'container_shortage': 203791, 'operation_number': 4321789}, exploration_params: {'epsilon': 0.11755102040816365}\n",
      "ep 82 - metrics: {'order_requirements': 2240000, 'container_shortage': 230472, 'operation_number': 4216193}, exploration_params: {'epsilon': 0.1110204081632657}\n",
      "ep 83 - metrics: {'order_requirements': 2240000, 'container_shortage': 148354, 'operation_number': 4274694}, exploration_params: {'epsilon': 0.10448979591836774}\n",
      "ep 84 - metrics: {'order_requirements': 2240000, 'container_shortage': 196658, 'operation_number': 4234519}, exploration_params: {'epsilon': 0.09795918367346979}\n",
      "ep 85 - metrics: {'order_requirements': 2240000, 'container_shortage': 117587, 'operation_number': 4409388}, exploration_params: {'epsilon': 0.09142857142857183}\n",
      "ep 86 - metrics: {'order_requirements': 2240000, 'container_shortage': 129900, 'operation_number': 4370451}, exploration_params: {'epsilon': 0.08489795918367388}\n",
      "ep 87 - metrics: {'order_requirements': 2240000, 'container_shortage': 150391, 'operation_number': 4372565}, exploration_params: {'epsilon': 0.07836734693877592}\n",
      "ep 88 - metrics: {'order_requirements': 2240000, 'container_shortage': 240991, 'operation_number': 4263189}, exploration_params: {'epsilon': 0.07183673469387797}\n",
      "ep 89 - metrics: {'order_requirements': 2240000, 'container_shortage': 108313, 'operation_number': 4400742}, exploration_params: {'epsilon': 0.06530612244898001}\n",
      "ep 90 - metrics: {'order_requirements': 2240000, 'container_shortage': 153466, 'operation_number': 4211634}, exploration_params: {'epsilon': 0.05877551020408205}\n",
      "ep 91 - metrics: {'order_requirements': 2240000, 'container_shortage': 144307, 'operation_number': 4295363}, exploration_params: {'epsilon': 0.05224489795918409}\n",
      "ep 92 - metrics: {'order_requirements': 2240000, 'container_shortage': 135912, 'operation_number': 4270395}, exploration_params: {'epsilon': 0.04571428571428613}\n",
      "ep 93 - metrics: {'order_requirements': 2240000, 'container_shortage': 130515, 'operation_number': 4309926}, exploration_params: {'epsilon': 0.03918367346938817}\n",
      "ep 94 - metrics: {'order_requirements': 2240000, 'container_shortage': 129339, 'operation_number': 4209056}, exploration_params: {'epsilon': 0.03265306122449021}\n",
      "ep 95 - metrics: {'order_requirements': 2240000, 'container_shortage': 134269, 'operation_number': 4254431}, exploration_params: {'epsilon': 0.026122448979592247}\n",
      "ep 96 - metrics: {'order_requirements': 2240000, 'container_shortage': 104881, 'operation_number': 4244267}, exploration_params: {'epsilon': 0.019591836734694286}\n",
      "ep 97 - metrics: {'order_requirements': 2240000, 'container_shortage': 89076, 'operation_number': 4300194}, exploration_params: {'epsilon': 0.013061224489796327}\n",
      "ep 98 - metrics: {'order_requirements': 2240000, 'container_shortage': 94324, 'operation_number': 4267081}, exploration_params: {'epsilon': 0.006530612244898367}\n",
      "ep 99 - metrics: {'order_requirements': 2240000, 'container_shortage': 88931, 'operation_number': 4267048}, exploration_params: {'epsilon': 4.0766001685454967e-16}\n"
     ]
    }
   ],
   "source": [
    "from maro.simulator import Env\n",
    "from maro.rl import MultiAgentWrapper, TwoPhaseLinearParameterScheduler\n",
    "\n",
    "# Step 1: create a CIM environment for a toy dataset\n",
    "env = Env(\"cim\", \"toy.4p_ssdd_l0.0\", durations=1120)\n",
    "agent_id_list = [str(agent_id) for agent_id in env.agent_idx_list]\n",
    "\n",
    "# Step 2: create DQN agents and shapers\n",
    "agent = MultiAgentWrapper(create_dqn_agents(agent_id_list))\n",
    "state_shaper = CIMStateShaper(look_back=7, max_ports_downstream=2)\n",
    "action_shaper = CIMActionShaper(action_space=list(np.linspace(-1.0, 1.0, 21)))\n",
    "experience_shaper = CIMExperienceShaper(time_window=100, fulfillment_factor=1.0, shortage_factor=1.0, time_decay_factor=0.97)\n",
    "\n",
    "# Step 3: training loop\n",
    "scheduler = TwoPhaseLinearParameterScheduler(\n",
    "    max_iter=100,\n",
    "    parameter_names=[\"epsilon\"],\n",
    "    split_ep=50,\n",
    "    start_values=0.4,\n",
    "    mid_values=0.32,\n",
    "    end_values=.0\n",
    ")\n",
    "\n",
    "executor = SimpleRolloutExecutor(env, agent, state_shaper, action_shaper, experience_shaper)\n",
    "for exploration_params in scheduler:\n",
    "    agent.set_exploration_params(exploration_params)\n",
    "    exp_by_agent = executor.roll_out(scheduler.iter)\n",
    "    print(f\"ep {scheduler.iter} - metrics: {env.metrics}, exploration_params: {exploration_params}\")\n",
    "    for agent_id, exp in exp_by_agent.items():\n",
    "        exp.update({\"loss\": [1e8] * len(list(exp.values())[0])})\n",
    "        agent[agent_id].store_experiences(exp)\n",
    "\n",
    "    for dqn in agent.agent_dict.values():\n",
    "        dqn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maro",
   "language": "python",
   "name": "maro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
